{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2   \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_model = cv2.face.EigenFaceRecognizer_create()\n",
    "face_model = cv2.face.LBPHFaceRecognizer_create()\n",
    "# face_model.read('facemodel.xml')\n",
    "face_model.read('facemodel.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = 'test.jpg'\n",
    "\n",
    "feature_size = (96, 96) \n",
    "\n",
    "label_file = './labels.csv'\n",
    "df = pd.read_csv(label_file)\n",
    "y_label = df.name\n",
    "\n",
    "\n",
    "def detect_faces(image):\n",
    "#     casc_file = \"lbpcascade_frontalface.xml\"\n",
    "    casc_file = \"haarcascade_frontalface_default.xml\"\n",
    "    frontal_face= cv2.CascadeClassifier(casc_file)\n",
    "    bBoxes= frontal_face.detectMultiScale(image, scaleFactor=1.2, \n",
    "        minNeighbors=5, minSize=(30, 30)  \n",
    "                        )\n",
    "    return bBoxes\n",
    "\n",
    "color_image = cv2.imread(image_file)\n",
    "dimensions = color_image.shape\n",
    "print(dimensions)\n",
    "img_resize_factor = 800 / dimensions[1] \n",
    "\n",
    "color_image = cv2.resize(color_image, None,fx=img_resize_factor,\n",
    "               fy=img_resize_factor,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "gray_frame = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "bBoxes = detect_faces(gray_frame)\n",
    "\n",
    "for bBox in bBoxes:\n",
    "    (p,q,r,s)= bBox\n",
    "    cv2.rectangle(color_image, (p,q), (p+r,q+s), (25,255,25), 2)\n",
    "\n",
    "\n",
    "    crop_image = gray_frame[q:q+s, p:p+r]\n",
    "\n",
    "    crop_image = cv2.resize(crop_image, feature_size) # ksb\n",
    "\n",
    "\n",
    "\n",
    "    [pred_label, pred_conf] = face_model.predict(crop_image)\n",
    "    print(\"Predicted person: {:8}\".format(y_label[pred_label]))\n",
    "\n",
    "\n",
    "    box_bg = (0, 255, 0)\n",
    "    box_bg = (0, 180, 0)\n",
    "    cv2.rectangle(color_image, (p,q), (p+95,q-22), box_bg, cv2.FILLED)\n",
    "    \n",
    "\n",
    "    box_text= y_label[pred_label][:7]\n",
    "    txt_color = (255,255,255)\n",
    "    cv2.putText(color_image, box_text, (p+4, q-4), \n",
    "                cv2.FONT_HERSHEY_PLAIN, 1.3, txt_color, 2)\n",
    "\n",
    "\n",
    "cv2.imwrite('pred_imgb.jpg', color_image, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "cv2.imshow(\"Win\", color_image )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VDO and Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scale = 0.5  \n",
    "feature_size = (96, 96) \n",
    "\n",
    "\n",
    "label_file = './labels.csv'\n",
    "df = pd.read_csv(label_file)\n",
    "y_label = df.name\n",
    "\n",
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "# casc_file = 'lbpcascade_frontalface.xml'\n",
    "frontal_face = cv2.CascadeClassifier(casc_file)  # Create the haar cascade\n",
    "\n",
    "faces = []\n",
    "\n",
    "cap = cv2.VideoCapture(0) # cam\n",
    "cap.set(3, 640) \n",
    "cap.set(4, 420) \n",
    "\n",
    "\n",
    "if (cap.isOpened()== False):  \n",
    "    print(\"Could not open the VDO file\") \n",
    "\n",
    "\n",
    "def detect_faces(image):\n",
    "    bBoxes = frontal_face.detectMultiScale(image, scaleFactor=1.3, \n",
    "        minNeighbors=5, minSize=(30, 30)) \n",
    "    return bBoxes    \n",
    "    \n",
    "frame_counter = 0\n",
    "while(cap.isOpened()): \n",
    "    ret, frame = cap.read() \n",
    "\n",
    "    if ret == True: \n",
    "        color_image = frame\n",
    "        frame_counter += 1\n",
    "\n",
    "        if frame_counter >= cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "            frame_counter = 0 \n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            \n",
    "        color_image = cv2.resize(color_image, None,fx=scale,fy=scale,\n",
    "                                 interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        if (frame_counter % 5) == 0:\n",
    "\n",
    "            gray_frame = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "            bBoxes = detect_faces(gray_frame)\n",
    "            for bBox in bBoxes:\n",
    "                (p,q,r,s)= bBox\n",
    "                \n",
    "                cv2.rectangle(color_image, (p,q), (p+r,q+s), (25,255,25), 2)\n",
    "\n",
    "\n",
    "                crop_image = gray_frame[q:q+s, p:p+r]\n",
    "\n",
    "                crop_image = cv2.resize(crop_image, feature_size) # ksb\n",
    "                [pred_label, pred_conf]= face_model.predict(crop_image)\n",
    "\n",
    "                box_bg = (0, 255, 0)\n",
    "                cv2.rectangle(color_image, (p,q), (p+95,q-22), box_bg, cv2.FILLED)\n",
    "\n",
    "                box_text= y_label[pred_label][:7]\n",
    "                txt_color = (100,0,215)\n",
    "                cv2.putText(color_image, box_text, (p+4, q-4), \n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1.3, txt_color, 2)\n",
    "\n",
    "            cv2.imshow('Mywindow', color_image) \n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == 27: \n",
    "            break\n",
    "   \n",
    "    else:  # if ret true\n",
    "        break\n",
    "   \n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scale = 0.5  \n",
    "feature_size = (96, 96) \n",
    "\n",
    "\n",
    "label_file = './labels.csv'\n",
    "df = pd.read_csv(label_file)\n",
    "y_label = df.name\n",
    "\n",
    "casc_file = \"haarcascade_frontalface_default.xml\"\n",
    "# casc_file = 'lbpcascade_frontalface.xml'\n",
    "frontal_face = cv2.CascadeClassifier(casc_file) \n",
    "\n",
    "faces = []\n",
    "\n",
    "cap = cv2.VideoCapture('test.mp4')  \n",
    "# cap.set(3, 640) \n",
    "# cap.set(4, 420) \n",
    "\n",
    "\n",
    "if (cap.isOpened()== False):  \n",
    "    print(\"Could not open the VDO file\") \n",
    "\n",
    "\n",
    "def detect_faces(image):\n",
    "    bBoxes = frontal_face.detectMultiScale(image, scaleFactor=1.3, \n",
    "        minNeighbors=5, minSize=(30, 30))  # ,flags = cv.CV_HAAR_SCALE_IMAGE\n",
    "    return bBoxes    \n",
    "    \n",
    "frame_counter = 0\n",
    "while(cap.isOpened()): \n",
    "\n",
    "    ret, frame = cap.read() \n",
    "\n",
    "    if ret == True: \n",
    "        color_image = frame\n",
    "        frame_counter += 1\n",
    "        # if block below is not used with CAM\n",
    "        if frame_counter >= cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "            frame_counter = 0 # \n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "           \n",
    "        color_image = cv2.resize(color_image, None,fx=scale,fy=scale,\n",
    "                                 interpolation=cv2.INTER_AREA)\n",
    "        gray_frame = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "        bBoxes = detect_faces(gray_frame)\n",
    "        for bBox in bBoxes:\n",
    "            (p,q,r,s)= bBox\n",
    "            cv2.rectangle(color_image, (p,q), (p+r,q+s), (25,255,25), 2)\n",
    "\n",
    "\n",
    "            crop_image = gray_frame[q:q+s, p:p+r]\n",
    "            crop_image = cv2.resize(crop_image, feature_size) # ksb\n",
    "\n",
    "            [pred_label, pred_conf]= face_model.predict(crop_image)\n",
    "\n",
    "            box_bg = (0, 255, 0)\n",
    "            cv2.rectangle(color_image, (p,q), (p+95,q-22), box_bg, cv2.FILLED)\n",
    "\n",
    "            box_text= y_label[pred_label][:7]\n",
    "            txt_color = (100,0,215)\n",
    "            cv2.putText(color_image, box_text, (p+4, q-4), \n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1.3, txt_color, 2)\n",
    "\n",
    "            cv2.imshow('Mywindow', color_image) \n",
    "\n",
    "        if cv2.waitKey(6) & 0xFF == 27:   # wait 200 is ok for Cam\n",
    "            break\n",
    "   \n",
    "    else:  # if ret true\n",
    "        break\n",
    "   \n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
